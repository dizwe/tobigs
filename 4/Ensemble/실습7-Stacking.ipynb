{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"./tatanic_X_train.npy\")\n",
    "y = np.load(\"./tatanic_y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator1 = XGBClassifier(max_depth=3, learning_rate=0.5, n_estimators=50, n_jobs=-1)\n",
    "estimator2 = LGBMClassifier(max_depth=2, learning_rate=0.5, n_estimators=50, n_jobs=-1)\n",
    "estimator3 = RandomForestClassifier(n_estimators=500, max_depth=3, n_jobs=-1)\n",
    "estimator4 = SVC(probability=True)\n",
    "# estimator5 = MLPClassifier(hidden_layer_sizes=(512,256, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimators = [estimator1, estimator2, estimator3, estimator4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((533, 27), (356, 27), (533,), (356,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator in base_estimators:\n",
    "            estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88502073, 0.11497927],\n",
       "       [0.9078408 , 0.09215921],\n",
       "       [0.3092692 , 0.6907308 ],\n",
       "       [0.9308935 , 0.0691065 ],\n",
       "       [0.00272995, 0.99727005],\n",
       "       [0.60250175, 0.39749828],\n",
       "       [0.930884  , 0.06911601],\n",
       "       [0.04314405, 0.95685595],\n",
       "       [0.8591654 , 0.14083464],\n",
       "       [0.09440607, 0.90559393],\n",
       "       [0.2622971 , 0.7377029 ],\n",
       "       [0.91105944, 0.08894058],\n",
       "       [0.929312  , 0.07068798],\n",
       "       [0.6191321 , 0.3808679 ],\n",
       "       [0.94228745, 0.05771256],\n",
       "       [0.9678691 , 0.03213092],\n",
       "       [0.91105944, 0.08894058],\n",
       "       [0.37348413, 0.62651587],\n",
       "       [0.0027954 , 0.9972046 ],\n",
       "       [0.94906527, 0.05093472],\n",
       "       [0.04280436, 0.95719564],\n",
       "       [0.17066634, 0.82933366],\n",
       "       [0.024216  , 0.975784  ],\n",
       "       [0.9305407 , 0.06945929],\n",
       "       [0.5432937 , 0.45670632],\n",
       "       [0.9936541 , 0.00634591],\n",
       "       [0.8636065 , 0.13639347],\n",
       "       [0.978336  , 0.021664  ],\n",
       "       [0.00518304, 0.99481696],\n",
       "       [0.9467569 , 0.0532431 ],\n",
       "       [0.4449044 , 0.5550956 ],\n",
       "       [0.97078204, 0.02921794],\n",
       "       [0.00738621, 0.9926138 ],\n",
       "       [0.01836467, 0.98163533],\n",
       "       [0.01029372, 0.9897063 ],\n",
       "       [0.98460466, 0.01539534],\n",
       "       [0.9959911 , 0.00400888],\n",
       "       [0.02549797, 0.974502  ],\n",
       "       [0.8367274 , 0.1632726 ],\n",
       "       [0.48867792, 0.5113221 ],\n",
       "       [0.4594506 , 0.5405494 ],\n",
       "       [0.97048056, 0.02951945],\n",
       "       [0.9421377 , 0.05786226],\n",
       "       [0.9705057 , 0.02949426],\n",
       "       [0.00331217, 0.9966878 ],\n",
       "       [0.21418059, 0.7858194 ],\n",
       "       [0.7966187 , 0.20338127],\n",
       "       [0.98674303, 0.01325699],\n",
       "       [0.88502073, 0.11497927],\n",
       "       [0.92381257, 0.07618743],\n",
       "       [0.59742385, 0.40257615],\n",
       "       [0.56926227, 0.4307377 ],\n",
       "       [0.9284596 , 0.07154043],\n",
       "       [0.00114226, 0.99885774],\n",
       "       [0.910174  , 0.08982597],\n",
       "       [0.95615625, 0.04384378],\n",
       "       [0.63040566, 0.36959437],\n",
       "       [0.9217517 , 0.07824831],\n",
       "       [0.98822117, 0.01177886],\n",
       "       [0.32481545, 0.67518455],\n",
       "       [0.6962861 , 0.30371392],\n",
       "       [0.00420582, 0.9957942 ],\n",
       "       [0.8567527 , 0.14324732],\n",
       "       [0.88502073, 0.11497927],\n",
       "       [0.6719791 , 0.32802087],\n",
       "       [0.48586565, 0.51413435],\n",
       "       [0.16320902, 0.836791  ],\n",
       "       [0.9097354 , 0.0902646 ],\n",
       "       [0.47682828, 0.5231717 ],\n",
       "       [0.46484274, 0.53515726],\n",
       "       [0.7309922 , 0.26900783],\n",
       "       [0.91109717, 0.08890283],\n",
       "       [0.8069777 , 0.1930223 ],\n",
       "       [0.00279737, 0.99720263],\n",
       "       [0.98954153, 0.01045845],\n",
       "       [0.20721328, 0.7927867 ],\n",
       "       [0.91105944, 0.08894058],\n",
       "       [0.59206605, 0.40793395],\n",
       "       [0.85928905, 0.14071096],\n",
       "       [0.02433771, 0.9756623 ],\n",
       "       [0.6725846 , 0.3274154 ],\n",
       "       [0.24136811, 0.7586319 ],\n",
       "       [0.7514355 , 0.24856448],\n",
       "       [0.98074657, 0.01925342],\n",
       "       [0.93621075, 0.06378926],\n",
       "       [0.1967017 , 0.8032983 ],\n",
       "       [0.9122027 , 0.08779726],\n",
       "       [0.01549494, 0.98450506],\n",
       "       [0.5723192 , 0.4276808 ],\n",
       "       [0.07546943, 0.92453057],\n",
       "       [0.93165797, 0.06834203],\n",
       "       [0.9217628 , 0.07823716],\n",
       "       [0.9217517 , 0.07824831],\n",
       "       [0.04966831, 0.9503317 ],\n",
       "       [0.5298258 , 0.47017422],\n",
       "       [0.01490915, 0.98509085],\n",
       "       [0.59206605, 0.40793395],\n",
       "       [0.9467569 , 0.0532431 ],\n",
       "       [0.19443452, 0.8055655 ],\n",
       "       [0.9353299 , 0.06467007],\n",
       "       [0.7068042 , 0.29319578],\n",
       "       [0.8963229 , 0.10367711],\n",
       "       [0.96913683, 0.03086319],\n",
       "       [0.9434398 , 0.05656024],\n",
       "       [0.9718707 , 0.02812925],\n",
       "       [0.02335799, 0.976642  ],\n",
       "       [0.08357722, 0.9164228 ],\n",
       "       [0.4763739 , 0.5236261 ],\n",
       "       [0.62479454, 0.37520546],\n",
       "       [0.9655141 , 0.03448588],\n",
       "       [0.00124741, 0.9987526 ],\n",
       "       [0.94148827, 0.05851176],\n",
       "       [0.86167043, 0.13832955],\n",
       "       [0.07285899, 0.927141  ],\n",
       "       [0.0064733 , 0.9935267 ],\n",
       "       [0.15978605, 0.84021395],\n",
       "       [0.6471983 , 0.3528017 ],\n",
       "       [0.86271614, 0.13728388],\n",
       "       [0.9512171 , 0.04878287],\n",
       "       [0.79840136, 0.20159867],\n",
       "       [0.2825141 , 0.7174859 ],\n",
       "       [0.79235655, 0.20764346],\n",
       "       [0.8315474 , 0.16845259],\n",
       "       [0.8550352 , 0.14496478],\n",
       "       [0.9308935 , 0.0691065 ],\n",
       "       [0.20561188, 0.7943881 ],\n",
       "       [0.6778604 , 0.3221396 ],\n",
       "       [0.31269896, 0.68730104],\n",
       "       [0.95880735, 0.04119267],\n",
       "       [0.92234516, 0.07765482],\n",
       "       [0.9838298 , 0.01617021],\n",
       "       [0.01083052, 0.9891695 ],\n",
       "       [0.9078408 , 0.09215921],\n",
       "       [0.4763739 , 0.5236261 ],\n",
       "       [0.9217517 , 0.07824831],\n",
       "       [0.0029254 , 0.9970746 ],\n",
       "       [0.3659985 , 0.6340015 ],\n",
       "       [0.9456846 , 0.05431539],\n",
       "       [0.8162951 , 0.18370493],\n",
       "       [0.00906861, 0.9909314 ],\n",
       "       [0.95007837, 0.04992165],\n",
       "       [0.02982223, 0.97017777],\n",
       "       [0.89462346, 0.10537655],\n",
       "       [0.05501777, 0.94498223],\n",
       "       [0.7198909 , 0.2801091 ],\n",
       "       [0.34291238, 0.6570876 ],\n",
       "       [0.2011922 , 0.7988078 ],\n",
       "       [0.09101385, 0.90898615],\n",
       "       [0.98420304, 0.01579695],\n",
       "       [0.008196  , 0.991804  ],\n",
       "       [0.40805465, 0.59194535],\n",
       "       [0.6540003 , 0.34599975],\n",
       "       [0.98074657, 0.01925342],\n",
       "       [0.92450535, 0.07549462],\n",
       "       [0.9467569 , 0.0532431 ],\n",
       "       [0.8353151 , 0.16468486],\n",
       "       [0.8369166 , 0.16308339],\n",
       "       [0.98001844, 0.01998156],\n",
       "       [0.9681272 , 0.03187279],\n",
       "       [0.9722807 , 0.02771934],\n",
       "       [0.6038207 , 0.39617935],\n",
       "       [0.19185883, 0.8081412 ],\n",
       "       [0.9718707 , 0.02812925],\n",
       "       [0.8918384 , 0.10816162],\n",
       "       [0.9000104 , 0.09998957],\n",
       "       [0.9705554 , 0.02944459],\n",
       "       [0.0208171 , 0.9791829 ],\n",
       "       [0.88502073, 0.11497927],\n",
       "       [0.02218425, 0.97781575],\n",
       "       [0.25514132, 0.7448587 ],\n",
       "       [0.9187732 , 0.08122683],\n",
       "       [0.01015067, 0.9898493 ],\n",
       "       [0.9412753 , 0.05872468],\n",
       "       [0.9598999 , 0.04010009],\n",
       "       [0.00308394, 0.99691606],\n",
       "       [0.88830614, 0.11169388],\n",
       "       [0.00416577, 0.99583423],\n",
       "       [0.46073866, 0.53926134],\n",
       "       [0.99525976, 0.00474024],\n",
       "       [0.4449044 , 0.5550956 ],\n",
       "       [0.02335441, 0.9766456 ],\n",
       "       [0.00468117, 0.99531883],\n",
       "       [0.91105944, 0.08894058],\n",
       "       [0.51759195, 0.48240805],\n",
       "       [0.9217759 , 0.07822414],\n",
       "       [0.97667336, 0.02332662],\n",
       "       [0.18298984, 0.81701016],\n",
       "       [0.37348413, 0.62651587],\n",
       "       [0.00563753, 0.9943625 ],\n",
       "       [0.8901987 , 0.10980128],\n",
       "       [0.74901897, 0.25098103],\n",
       "       [0.9467569 , 0.0532431 ],\n",
       "       [0.01133293, 0.9886671 ],\n",
       "       [0.02499396, 0.97500604],\n",
       "       [0.98822117, 0.01177886],\n",
       "       [0.99361527, 0.00638475],\n",
       "       [0.31339496, 0.68660504],\n",
       "       [0.39429134, 0.60570866],\n",
       "       [0.59460926, 0.40539074],\n",
       "       [0.1640448 , 0.8359552 ],\n",
       "       [0.03499031, 0.9650097 ],\n",
       "       [0.91105944, 0.08894058],\n",
       "       [0.7003569 , 0.2996431 ],\n",
       "       [0.888484  , 0.111516  ],\n",
       "       [0.9467569 , 0.0532431 ],\n",
       "       [0.8104985 , 0.18950151],\n",
       "       [0.2542587 , 0.7457413 ],\n",
       "       [0.80808604, 0.19191399],\n",
       "       [0.03716117, 0.9628388 ],\n",
       "       [0.00123584, 0.99876416],\n",
       "       [0.8160738 , 0.1839262 ],\n",
       "       [0.9947247 , 0.00527529],\n",
       "       [0.00910711, 0.9908929 ],\n",
       "       [0.8196819 , 0.18031815],\n",
       "       [0.71871936, 0.28128064],\n",
       "       [0.04579389, 0.9542061 ],\n",
       "       [0.59742385, 0.40257615],\n",
       "       [0.92981505, 0.07018495],\n",
       "       [0.88830614, 0.11169388],\n",
       "       [0.00188035, 0.99811965],\n",
       "       [0.01015067, 0.9898493 ],\n",
       "       [0.02961999, 0.97038   ],\n",
       "       [0.9887189 , 0.01128109],\n",
       "       [0.9816904 , 0.01830961],\n",
       "       [0.00152534, 0.99847466],\n",
       "       [0.73142546, 0.26857454],\n",
       "       [0.97159326, 0.02840676],\n",
       "       [0.69048274, 0.3095173 ],\n",
       "       [0.92075866, 0.07924134],\n",
       "       [0.00188279, 0.9981172 ],\n",
       "       [0.991523  , 0.00847696],\n",
       "       [0.99361527, 0.00638475],\n",
       "       [0.75519866, 0.24480136],\n",
       "       [0.95880735, 0.04119267],\n",
       "       [0.9643373 , 0.03566271],\n",
       "       [0.6540003 , 0.34599975],\n",
       "       [0.9269171 , 0.07308292],\n",
       "       [0.02635103, 0.97364897],\n",
       "       [0.93722385, 0.06277613],\n",
       "       [0.18534213, 0.81465787],\n",
       "       [0.6854942 , 0.31450585],\n",
       "       [0.00645757, 0.99354243],\n",
       "       [0.9106288 , 0.08937121],\n",
       "       [0.00451201, 0.995488  ],\n",
       "       [0.9718707 , 0.02812925],\n",
       "       [0.0027954 , 0.9972046 ],\n",
       "       [0.98822117, 0.01177886],\n",
       "       [0.2890442 , 0.7109558 ],\n",
       "       [0.06570029, 0.9342997 ],\n",
       "       [0.86435485, 0.13564512],\n",
       "       [0.01279902, 0.987201  ],\n",
       "       [0.5298258 , 0.47017422],\n",
       "       [0.8901987 , 0.10980128],\n",
       "       [0.0287261 , 0.9712739 ],\n",
       "       [0.95507234, 0.04492768],\n",
       "       [0.01165289, 0.9883471 ],\n",
       "       [0.82698107, 0.17301893],\n",
       "       [0.99136436, 0.00863565],\n",
       "       [0.0722217 , 0.9277783 ],\n",
       "       [0.65962595, 0.34037405],\n",
       "       [0.77427846, 0.22572152],\n",
       "       [0.02589291, 0.9741071 ],\n",
       "       [0.2191031 , 0.7808969 ],\n",
       "       [0.09711725, 0.90288275],\n",
       "       [0.97948927, 0.02051071],\n",
       "       [0.9503855 , 0.04961449],\n",
       "       [0.8348    , 0.16520001],\n",
       "       [0.01133293, 0.9886671 ],\n",
       "       [0.82698107, 0.17301893],\n",
       "       [0.3133617 , 0.6866383 ],\n",
       "       [0.77446437, 0.2255356 ],\n",
       "       [0.93621075, 0.06378926],\n",
       "       [0.88502073, 0.11497927],\n",
       "       [0.9872603 , 0.01273972],\n",
       "       [0.9458472 , 0.05415278],\n",
       "       [0.17066634, 0.82933366],\n",
       "       [0.08991969, 0.9100803 ],\n",
       "       [0.9742352 , 0.02576481],\n",
       "       [0.00415939, 0.9958406 ],\n",
       "       [0.9467569 , 0.0532431 ],\n",
       "       [0.0020386 , 0.9979614 ],\n",
       "       [0.88393193, 0.11606806],\n",
       "       [0.23774505, 0.76225495],\n",
       "       [0.88612413, 0.11387587],\n",
       "       [0.9887189 , 0.01128109],\n",
       "       [0.30190527, 0.6980947 ],\n",
       "       [0.88945425, 0.11054578],\n",
       "       [0.00984311, 0.9901569 ],\n",
       "       [0.00124741, 0.9987526 ],\n",
       "       [0.9648732 , 0.03512683],\n",
       "       [0.98270917, 0.01729083],\n",
       "       [0.08846003, 0.91154   ],\n",
       "       [0.97274923, 0.02725074],\n",
       "       [0.9297354 , 0.07026455],\n",
       "       [0.8968197 , 0.10318028],\n",
       "       [0.03177339, 0.9682266 ],\n",
       "       [0.99375486, 0.00624516],\n",
       "       [0.05208415, 0.94791585],\n",
       "       [0.99121946, 0.00878056],\n",
       "       [0.97693706, 0.02306293],\n",
       "       [0.9945705 , 0.00542948],\n",
       "       [0.96999335, 0.03000665],\n",
       "       [0.6563524 , 0.34364763],\n",
       "       [0.8636065 , 0.13639347],\n",
       "       [0.02855545, 0.97144455],\n",
       "       [0.01441288, 0.9855871 ],\n",
       "       [0.16272551, 0.8372745 ],\n",
       "       [0.8454415 , 0.1545585 ],\n",
       "       [0.91695136, 0.08304862],\n",
       "       [0.6976639 , 0.3023361 ],\n",
       "       [0.3979423 , 0.6020577 ],\n",
       "       [0.9686982 , 0.0313018 ],\n",
       "       [0.79235655, 0.20764346],\n",
       "       [0.7841305 , 0.21586949],\n",
       "       [0.3989793 , 0.6010207 ],\n",
       "       [0.02583271, 0.9741673 ],\n",
       "       [0.1526984 , 0.8473016 ],\n",
       "       [0.8108138 , 0.1891862 ],\n",
       "       [0.9619694 , 0.03803064],\n",
       "       [0.49481934, 0.50518066],\n",
       "       [0.95464104, 0.04535896],\n",
       "       [0.9319665 , 0.06803353],\n",
       "       [0.02337027, 0.97662973],\n",
       "       [0.62399966, 0.37600034],\n",
       "       [0.49481934, 0.50518066],\n",
       "       [0.04365587, 0.9563441 ],\n",
       "       [0.00940466, 0.99059534],\n",
       "       [0.9741071 , 0.02589291],\n",
       "       [0.50133765, 0.49866235],\n",
       "       [0.7400521 , 0.25994793],\n",
       "       [0.5057216 , 0.49427837],\n",
       "       [0.10106641, 0.8989336 ],\n",
       "       [0.74630576, 0.25369424],\n",
       "       [0.9477293 , 0.05227072],\n",
       "       [0.9485573 , 0.05144268],\n",
       "       [0.96654105, 0.03345896],\n",
       "       [0.98822117, 0.01177886],\n",
       "       [0.7437197 , 0.25628027],\n",
       "       [0.91105944, 0.08894058],\n",
       "       [0.909454  , 0.09054602],\n",
       "       [0.8532865 , 0.14671351],\n",
       "       [0.8342139 , 0.16578609],\n",
       "       [0.9956802 , 0.00431977],\n",
       "       [0.3668487 , 0.6331513 ],\n",
       "       [0.98822117, 0.01177886],\n",
       "       [0.8163183 , 0.18368176],\n",
       "       [0.03891075, 0.96108925],\n",
       "       [0.97250885, 0.02749114],\n",
       "       [0.7514355 , 0.24856448],\n",
       "       [0.81573904, 0.18426093],\n",
       "       [0.91762197, 0.08237801],\n",
       "       [0.0937826 , 0.9062174 ],\n",
       "       [0.990822  , 0.00917801],\n",
       "       [0.2256676 , 0.7743324 ],\n",
       "       [0.1526984 , 0.8473016 ],\n",
       "       [0.9800648 , 0.0199352 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 데이터를 클래스 아니면 활률 값으로 바꿈(즉 X 데이터를 확률 데이터로 바꾼다.)\n",
    "base_estimators[0].predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측한 class 자체를 다시 또 학습한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_set = np.array([estimator.predict(X_test) for estimator in base_estimators]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_set # 356*5\n",
    "# phase 1. subset2로 다른 feature로 만들기 위한 모델을 subset1으로 학습한다.\n",
    "# subset도 다른 featureset으로 \n",
    "# 즉 vanilla ensemble처럼 데이터셋을 multiplicity voting 하는 것이 아니라 voting 하는 것 자체를 학습하자.\n",
    "# 다른 방법) subset2 가 subset1 한 걸로 결과값을 만드는 모델에서 거기에 더해서 원래 subset2에 있던 x feature도 concat해서 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8261904761904763\n",
      "0.8261904761904763\n",
      "0.8290476190476191\n",
      "0.8261904761904763\n"
     ]
    }
   ],
   "source": [
    "for estimator in base_estimators:\n",
    "    result = cross_val_score(estimator, meta_train_set, y_test, scoring=\"accuracy\" , cv=5).mean()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train_set2 = np.array([estimator.predict_proba(X_test)[:,1] for estimator in base_estimators]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11497927, 0.12179135, 0.14172594, 0.15354737],\n",
       "       [0.09215921, 0.09122816, 0.13298038, 0.15323276],\n",
       "       [0.69073081, 0.66027134, 0.65642621, 0.76662845],\n",
       "       ...,\n",
       "       [0.7743324 , 0.67166478, 0.71000297, 0.80446644],\n",
       "       [0.8473016 , 0.71126666, 0.56628192, 0.7423236 ],\n",
       "       [0.0199352 , 0.03801907, 0.29348125, 0.23871014]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train_set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8148412698412699\n",
      "0.8094444444444445\n",
      "0.8289682539682539\n",
      "0.8318253968253968\n"
     ]
    }
   ],
   "source": [
    "for estimator in base_estimators:\n",
    "    result = cross_val_score(estimator, meta_train_set2, y_test, scoring=\"accuracy\" , cv=5).mean()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 31)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_test = np.concatenate([X_test, meta_train_set2], axis = 1)\n",
    "new_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7980158730158731\n",
      "0.7923809523809523\n",
      "0.8234126984126984\n",
      "0.8123809523809523\n"
     ]
    }
   ],
   "source": [
    "for estimator in base_estimators:\n",
    "    result = cross_val_score(estimator, new_X_test, y_test, scoring=\"accuracy\" , cv=5).mean()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
